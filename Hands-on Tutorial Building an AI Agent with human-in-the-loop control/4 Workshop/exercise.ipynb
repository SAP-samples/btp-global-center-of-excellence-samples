{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "#Install all necessary dependencies. Select Python 3.13\n",
    "%pip install -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dependencies from helper file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -i helper.py\n",
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have real-time capabilities to provide the current date. You can check the date on your device or calendar.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Language Model\n",
    "llm = init_llm('gpt-4o', max_tokens=1024, temperature=0)\n",
    "# llm = init_llm('gemini-2.5-pro', max_tokens=4192, temperature=0, init_func=google_vertexai_init_chat_model)\n",
    "\n",
    "llm.invoke(\"What day is it?\").content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Give the Agent a function `get_today()` and invoke it asking about the date.\n",
    "\n",
    "<details>\n",
    "<summary>Show solution</summary>\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def get_today() -> str:\n",
    "    \"This tool retrieves the current date and time.\"\n",
    "    return date.today()\n",
    "\n",
    "tools = [get_today]\n",
    "tool_llm = llm.bind_tools(tools)\n",
    "answer = tool_llm.invoke(\"What's todays date?\")\n",
    "\n",
    "display(f\"AI Response: {answer.content}\" if answer.content else \"No AI Message.\")\n",
    "display(f\"AI Actions: {answer.additional_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No AI Message.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AI Actions: {\\'tool_calls\\': [{\\'id\\': \\'call_oloqS9zth4pMoTAMsgaGpcfU\\', \\'function\\': {\\'arguments\\': \\'{\"location\": \"New York\"}\\', \\'name\\': \\'get_current_weather\\'}, \\'type\\': \\'function\\'}, {\\'id\\': \\'call_cgeyoxDl3oLrT825XUO4cT0X\\', \\'function\\': {\\'arguments\\': \\'{\"location\": \"Los Angeles\"}\\', \\'name\\': \\'get_current_weather\\'}, \\'type\\': \\'function\\'}], \\'refusal\\': None}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Implement the function\n",
    "def get_today():\n",
    "    \"\"\"TODO: Define this docstring.\"\"\"\n",
    "    pass\n",
    "\n",
    "#Add the tool\n",
    "tools = []\n",
    "\n",
    "agent_llm = llm.bind_tools(tools)\n",
    "\n",
    "#Add message for the agent\n",
    "answer = agent_llm.invoke(\"\")\n",
    "\n",
    "display(f\"AI Response: {answer.content}\" if answer.content else \"No AI Message.\")\n",
    "display(f\"AI Actions: {answer.additional_kwargs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No AI Message.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"AI Actions: {'tool_calls': [{'id': 'call_0IqJJyuXbDdOpJ5IqOhia9iv', 'function': {'arguments': '{}', 'name': 'get_today'}, 'type': 'function'}], 'refusal': None}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SOLUTION TODO HIDE\n",
    "@tool\n",
    "def get_today() -> str:\n",
    "    \"This tool retrieves the current date and time.\"\n",
    "    return date.today()\n",
    "\n",
    "tools = [get_today]\n",
    "tool_llm = llm.bind_tools(tools)\n",
    "answer = tool_llm.invoke(\"What's todays date?\")\n",
    "\n",
    "display(f\"AI Response: {answer.content}\" if answer.content else \"No AI Message.\")\n",
    "display(f\"AI Actions: {answer.additional_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date is September 24, 2025.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "tools = [get_today]\n",
    "react_agent = create_react_agent(model=llm, tools=tools)\n",
    "answer = react_agent.invoke({\"messages\": [\"What's todays date?\"]})[\"messages\"]\n",
    "print(answer[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCV9fZW5kX18oWzxwPl9fZW5kX188L3A+XSk6OjpsYXN0CglfX3N0YXJ0X18gLS0+IGFnZW50OwoJdG9vbHMgLS0+IGFnZW50OwoJYWdlbnQgLS4tPiB0b29sczsKCWFnZW50IC0uLT4gX19lbmRfXzsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:320px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's todays date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_today (call_s5MXJMcDSvBCFtFwzZHtK51U)\n",
      " Call ID: call_s5MXJMcDSvBCFtFwzZHtK51U\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_today\n",
      "\n",
      "2025-09-24\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today's date is September 24, 2025.\n"
     ]
    }
   ],
   "source": [
    "display_graph(react_agent)\n",
    "for msg in answer:\n",
    "    msg.pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Tools for a LangGraph Agent**\n",
    "\n",
    "**The Critical Role of Docstrings**\n",
    "\n",
    "For a LangGraph agent to effectively use a custom function as a \"tool,\" it must first understand what the function does. The primary source of this understanding for the agent is the function's docstring. The LLM parses the docstring to learn the tool's purpose, its required parameters, and what kind of output to expect. A well-written docstring is therefore essential for the agent to know when and how to use the tool correctly.\n",
    "\n",
    "**Exercise: Documenting an Agent Tool**\n",
    "\n",
    "In the next cell, you will find a `get_records()` function designed to fetch data from an API. Your task is to understand the function and complete its docstring. \n",
    "\n",
    "(This exercise highlights how crucial clear documentation is, as it directly enables the agent to correctly utilize the function to fulfill user requests.)\n",
    "\n",
    "<details>\n",
    "<summary>Show solution </summary>\n",
    "\n",
    "```python\n",
    "\n",
    "odata_endpoint = os.getenv(\"ODATA_ENDPOINT\")\n",
    "if not odata_endpoint:\n",
    "    raise ValueError(\"ODATA_ENDPOINT environment variable is not set.\")\n",
    "\n",
    "@tool\n",
    "def get_records(top:int) -> str:\n",
    "    \"\"\"Fetch ExternalTimeData records for the current user.\n",
    "    Args:\n",
    "        top: Maximum number of records to return.\n",
    "    Returns:\n",
    "        JSON response with time records or error message.\n",
    "    \"\"\"\n",
    "    # Built query\n",
    "    params = {}\n",
    "    \n",
    "    # Limit number of records returned\n",
    "    if top is not None:\n",
    "        params['$top'] = top\n",
    "\n",
    "    # Filter by current userID\n",
    "    params['$filter'] = f'userId eq {user_id}'\n",
    "    query_text = urllib.parse.urlencode(params, safe='(),')\n",
    "\n",
    "    # Make GET request to the SuccessFactors OData API\n",
    "    table = 'ExternalTimeData'\n",
    "    url = f'{odata_endpoint}{table}?{query_text}'\n",
    "    response = requests.get(url, headers=get_header)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return f'Error: {response.content}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SuccessFactors OData API endpoint to fetch time records for the current user.\n",
    "odata_endpoint = os.getenv(\"ODATA_ENDPOINT\")\n",
    "if not odata_endpoint:\n",
    "    raise ValueError(\"ODATA_ENDPOINT environment variable is not set.\")\n",
    "\n",
    "@tool\n",
    "def get_records(top:int) -> str:\n",
    "    \"\"\"TODO Understand the function and fill in the docstring.\n",
    "    \"\"\"\n",
    "    # Built query\n",
    "    params = {}\n",
    "    \n",
    "    # Limit number of records returned\n",
    "    if top is not None:\n",
    "        params['$top'] = top\n",
    "\n",
    "    # Filter by current userID\n",
    "    params['$filter'] = f'userId eq {user_id}'\n",
    "    query_text = urllib.parse.urlencode(params, safe='(),')\n",
    "\n",
    "    # Make GET request to the SuccessFactors OData API\n",
    "    table = 'ExternalTimeData'\n",
    "    url = f'{odata_endpoint}{table}?{query_text}'\n",
    "    response = requests.get(url, headers=get_header)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return f'Error: {response.content}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SuccessFactors OData API endpoint to fetch time records for the current user.\n",
    "odata_endpoint = os.getenv(\"ODATA_ENDPOINT\")\n",
    "if not odata_endpoint:\n",
    "    raise ValueError(\"ODATA_ENDPOINT environment variable is not set.\")\n",
    "    \n",
    "@tool\n",
    "def get_records(top:int) -> str:\n",
    "    \"\"\"Fetch ExternalTimeData records for the current user.\n",
    "    Args:\n",
    "        top: Maximum number of records to return.\n",
    "    Returns:\n",
    "        JSON response with time records or error message.\n",
    "    \"\"\"\n",
    "    # Built query\n",
    "    params = {}\n",
    "    \n",
    "    # Limit number of records returned\n",
    "    if top is not None:\n",
    "        params['$top'] = top\n",
    "\n",
    "    # Filter by current userID\n",
    "    params['$filter'] = f'userId eq {user_id}'\n",
    "    query_text = urllib.parse.urlencode(params, safe='(),')\n",
    "\n",
    "    # Make GET request to the SuccessFactors OData API\n",
    "    table = 'ExternalTimeData'\n",
    "    url = f'{odata_endpoint}{table}?{query_text}'\n",
    "    response = requests.get(url, headers=get_header)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return f'Error: {response.content}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no time records available.\n"
     ]
    }
   ],
   "source": [
    "tools = [get_today, get_records]\n",
    "\n",
    "react_agent = create_react_agent(model=llm, tools=tools)\n",
    "answer = react_agent.invoke({\"messages\": [\"Get me the latest time records.\"]})[\"messages\"]\n",
    "print(answer[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No records so far. Let's add some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LangGraph requires typing information for structured data inputs/outputs. Define a TypedDict for the input data.\n",
    "\n",
    "class ExternalTimeData(TypedDict):\n",
    "    startDate: str\n",
    "    startTime: str\n",
    "    endTime: str\n",
    "\n",
    "@tool\n",
    "def post_records(data: ExternalTimeData, confirmation_message : str):\n",
    "    \"\"\"Post work time records to the API after user confirmation.\n",
    "\n",
    "    Args:\n",
    "        data: Dictionary with:\n",
    "            startDate: Date in 'YYYY-mm-dd' format.\n",
    "            startTime: ISO 8601 time string (e.g. 'PT09H00M00S').\n",
    "            endTime: ISO 8601 time string (e.g. 'PT18H30M00S').\n",
    "        confirmation_message: Detailed confirmation prompt for the user, including specific date and time.\n",
    "\n",
    "    Returns:\n",
    "        str: Success message if entity created, otherwise error details.\n",
    "    \"\"\"\n",
    "    # Build POST payload\n",
    "    payload, url = build_post_payload(data, odata_endpoint)\n",
    "    # Make POST request to the SuccessFactors OData API endpoint\n",
    "    response = requests.post(url, headers=post_header, json=payload)\n",
    "\n",
    "    # Process response\n",
    "    if response.status_code in (200, 201):\n",
    "        return f'Entity created successfully: {data}'\n",
    "    else:\n",
    "        return  f'Error creating entity ({data}):  {response.status_code}: {response.content}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Preparing Tool Inputs**\n",
    "\n",
    "An agent needs to know not just *what* a tool does, but also *how* to provide the correct inputs. The `post_records` function requires data in a specific format to log time entries.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "In the next cell, you'll find an `example_record`. Examine the `post_records` function and its docstring to understand the required data structure. Then, fill in the `example_record` with valid data. This exercise simulates how the agent prepares data before calling a tool.\n",
    "\n",
    "<details>\n",
    "<summary>Show solution</summary>\n",
    "\n",
    "```python\n",
    "# Create example record like the agent would\n",
    "example_record: ExternalTimeData = {\n",
    "    \"startDate\": \"2025-01-01\",\n",
    "    \"startTime\": \"PT09H00M00S\",\n",
    "    \"endTime\": \"PT18H30M00S\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid isoformat string: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO Create example record like the agent would\u001b[39;00m\n\u001b[0;32m      2\u001b[0m example_record: ExternalTimeData \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartDate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartTime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendTime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m }\n\u001b[1;32m----> 8\u001b[0m \u001b[43mpost_records\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_record\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfirmation_message\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo confirmation implemented yet.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\I761048\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:607\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    606\u001b[0m     tool_input, kwargs \u001b[38;5;241m=\u001b[39m _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\I761048\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:892\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[0;32m    891\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[0;32m    893\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[0;32m    894\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\I761048\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:861\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[0;32m    860\u001b[0m         tool_kwargs \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m {config_param: config}\n\u001b[1;32m--> 861\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\I761048\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\structured.py:103\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[1;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m    102\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStructuredTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m, in \u001b[0;36mpost_records\u001b[1;34m(data, confirmation_message)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Post work time records to the API after user confirmation.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    str: Success message if entity created, otherwise error details.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Build POST payload\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m payload, url \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_post_payload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43modata_endpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Make POST request to the SuccessFactors OData API endpoint\u001b[39;00m\n\u001b[0;32m     25\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, headers\u001b[38;5;241m=\u001b[39mpost_header, json\u001b[38;5;241m=\u001b[39mpayload)\n",
      "File \u001b[1;32m~\\Projects\\mee-samples\\Hands-on Tutorial Building an AI Agent with human-in-the-loop control\\1 Workshop\\helper.py:82\u001b[0m, in \u001b[0;36mbuild_post_payload\u001b[1;34m(data, base_url)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_post_payload\u001b[39m(data: ExternalTimeData, base_url):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Convert startDate to OData format and add userId\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(data)\n\u001b[1;32m---> 82\u001b[0m     payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Date(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromisoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstartDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtimestamp())\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m     payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternalCode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid1())\n\u001b[0;32m     84\u001b[0m     payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m user_id\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid isoformat string: ''"
     ]
    }
   ],
   "source": [
    "# TODO Create example record like the agent would\n",
    "example_record: ExternalTimeData = {\n",
    "    \"startDate\": \"\",\n",
    "    \"startTime\": \"\",\n",
    "    \"endTime\": \"\"\n",
    "}\n",
    "\n",
    "post_records.invoke({\"data\": example_record, \"confirmation_message\": \"No confirmation implemented yet.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Entity created successfully: {'startDate': '2025-01-01', 'startTime': 'PT09H00M00S', 'endTime': 'PT18H30M00S'}\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create example record like the agent would\n",
    "example_record: ExternalTimeData = {\n",
    "    \"startDate\": \"2025-01-01\",\n",
    "    \"startTime\": \"PT09H00M00S\",\n",
    "    \"endTime\": \"PT18H30M00S\"\n",
    "}\n",
    "\n",
    "post_records.invoke({\"data\": example_record, \"confirmation_message\": \"No confirmation implemented yet.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_today (call_yBMJVgLmseP7c2T2pgU1w7p7)\n",
      " Call ID: call_yBMJVgLmseP7c2T2pgU1w7p7\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_today\n",
      "\n",
      "2025-09-24\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  post_records (call_HggmM9FPeLqcbos0lK751QQI)\n",
      " Call ID: call_HggmM9FPeLqcbos0lK751QQI\n",
      "  Args:\n",
      "    data: {'startDate': '2025-09-24', 'startTime': 'PT09H00M00S', 'endTime': 'PT18H30M00S'}\n",
      "    confirmation_message: Please confirm the entry for work done on 2025-09-24 from 09:00 to 18:30.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: post_records\n",
      "\n",
      "Entity created successfully: {'startDate': '2025-09-24', 'startTime': 'PT09H00M00S', 'endTime': 'PT18H30M00S'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your work time entry for today, from 09:00 to 18:30, has been successfully logged into the system.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a react agent with all three tools\n",
    "tools = [get_today, get_records, post_records]\n",
    "react_agent = create_react_agent(model=llm, tools=tools)\n",
    "\n",
    "# Stream the agent's actions and final response\n",
    "# Modify the user input if you want to test different scenarios\n",
    "stream = react_agent.stream({\"messages\": [\"Today I worked from 09:00 to 18:30. Please log this time entry into the system.\"]})\n",
    "process_output(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Missing Human-In-The-Loop (HITL) control with the current tooling could lead to several issues:\n",
       "\n",
       "1. **Accuracy and Validation**: Automated tools like `functions.get_records` and `functions.post_records` may retrieve or post incorrect data without human validation, leading to errors in time tracking.\n",
       "\n",
       "2. **Confirmation and Consent**: The `functions.post_records` tool relies on user confirmation messages. Without HITL, there is a risk of miscommunication or misunderstanding, resulting in unintended actions.\n",
       "\n",
       "3. **Contextual Understanding**: Tools like `functions.get_today` provide data without context. HITL is essential for interpreting and making decisions based on this data.\n",
       "\n",
       "4. **Error Handling**: Automated tools may not handle unexpected errors or edge cases effectively, which could be mitigated by human intervention.\n",
       "\n",
       "5. **Security and Privacy**: Automated handling of sensitive data without human oversight could lead to security breaches or privacy violations.\n",
       "\n",
       "In summary, HITL control is crucial for ensuring accuracy, validation, contextual understanding, error handling, and security in the use of these tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "answer = react_agent.invoke({\"messages\": [\"What issues could arrise due to missing HITL control with your current tooling? Keep it concise. Mention your tools.\"]})\n",
    "display(Markdown(answer[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prebuilt `create_react_agent` lacks Human-in-the-Loop (HITL) control for sensitive operations like `post_records`. To address this, we'll build a custom agent from scratch using LangGraph's core components, which will also introduce you to the framework's fundamentals.\n",
    "\n",
    "Our custom agent will have a three-node architecture:\n",
    "\n",
    "- **Agent Node**: Decides the next action by calling the LLM.\n",
    "- **Review Node**: Acts as our HITL control, intercepting actions like `post_records` to ask for user confirmation.\n",
    "- **Tool Node**: Executes the approved tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCV9fZW5kX18oWzxwPl9fZW5kX188L3A+XSk6OjpsYXN0CglfX3N0YXJ0X18gLS0+IGFnZW50OwoJdG9vbHMgLS0+IGFnZW50OwoJYWdlbnQgLS4tPiB0b29sczsKCWFnZW50IC0uLT4gX19lbmRfXzsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:320px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we can see the current graph structure.\n",
    "# We want to add a node that allows human review before posting records.\n",
    "display_graph(react_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with agent node. Mimicks the prebuilt react agent node.\n",
    "def agent(state: AgentState, config: RunnableConfig):\n",
    "    model_input = prompt.invoke({'msg': state['messages']})\n",
    "    response = cast(AIMessage, agent_llm.invoke(model_input, config))\n",
    "    response.name = \"agent\"\n",
    "    return {\"messages\": [response]}\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define the review node. For simplicity, we use only text input for verification. A more robust approach (used in the actual demo) can be found in the appendix. Here we use an additional language model for verificication. \n",
    "We need use a workaround to get structured output from our model as of now structured_output is not supported. For this we bind a tool the model should use to structure its response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Crafting a System Prompt for Tool Enforcement**\n",
    "\n",
    "To ensure our verification LLM reliably uses the `UserAffirmation` tool for structured output, we need to provide a clear and strict system prompt. A well-defined prompt is crucial for forcing the model to adhere to a specific behavior—in this case, always calling the specified tool.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "In the next cell, complete the `system_prompt` variable. Your prompt should instruct the LLM on its role and explicitly command it to always use the `UserAffirmation` tool to structure its response, without exception.\n",
    "\n",
    "<details>\n",
    "<summary>Show solution</summary>\n",
    "\n",
    "```python\n",
    "system_prompt = \"\"\"You are a human-in-the-loop verification LLM. Your task is to determine whether the user has confirmed an action or not.\n",
    "You must always use the UserAffirmation tool to structure your response. Never provide a response without it and always call the tool.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification test results:\n",
      "\n",
      "✓ [Clear confirmation] 'Yes, proceed with logging' -> True (expected True) | The user has confirmed the action by stating 'Yes, proceed with logging.'\n",
      "✓ [Clear rejection] 'No, don't do that' -> False (expected False) | The user has explicitly stated 'No, don't do that', indicating they do not want to proceed with the action.\n",
      "✓ [Uncertainty] 'I'm not sure' -> False (expected False) | The user expressed uncertainty and did not confirm the action.\n",
      "✓ [Confirmation] 'Go ahead' -> True (expected True) | The user has confirmed the action by saying 'Go ahead'.\n",
      "✓ [Confirmation] 'That looks right' -> True (expected True) | The user confirmed the action by stating 'That looks right'.\n",
      "✓ [Hesitation] 'Wait, let me think' -> False (expected False) | The user has not confirmed the action and has requested more time to think.\n",
      "✓ [Strong confirmation] 'Perfect!' -> True (expected True) | The user has confirmed the action by responding with 'Perfect!' which indicates agreement and satisfaction.\n",
      "✓ [Rejection] 'Actually, no' -> False (expected False) | The user explicitly stated 'Actually, no', indicating that they have not confirmed the action.\n",
      "✓ [Indirect rejection] 'Maybe later' -> False (expected False) | The user has not confirmed the action and has indicated that they may consider it at a later time.\n"
     ]
    }
   ],
   "source": [
    "class UserAffirmation(BaseModel):\n",
    "    \"\"\"Always use this tool. It is necessary to structure your response.\"\"\"\n",
    "    user_affirmation: bool = Field(description=\"Whether the user confirmed the action.\")\n",
    "    explanation: str = Field(description=\"An explanation of your decision.\")\n",
    "\n",
    "verification_llm = llm.bind_tools([UserAffirmation])\n",
    "\n",
    "# TODO Define the system prompt for verification LLM. You must be very clear to always use the tool.\n",
    "system_prompt = \"\"\"You are a human-in-the-loop verification LLM. Your task is to determine whether the user has confirmed an action or not.\n",
    "You must always use the UserAffirmation tool to structure your response. Never provide a response without it and always call the tool.\"\"\"\n",
    "\n",
    "unit_test(verification_llm, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `human_review` node intercepts `post_records` tool calls to request user confirmation via an `interrupt`. If no such calls are present, control passes directly to the `tools` node.\n",
    "\n",
    "After the user responds to the interrupt, a verification LLM processes their input.\n",
    "- **If approved**, execution proceeds to the `tools` node.\n",
    "- **If denied**, a `ToolMessage` is added to the state, and control returns to the `agent` node.\n",
    "\n",
    "**Key Points:**\n",
    "- A `ToolMessage` is required for every tool call.\n",
    "- After an `interrupt`, the `human_review` node re-executes from the beginning, which is a common pitfall to be aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def human_review(state: AgentState) -> Command[Literal[\"agent\", \"tools\"]]:\n",
    "    # Check if the last message contains a call to post_records\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    post_record_calls = [tool_call for tool_call in last_message.tool_calls if tool_call['name'] == 'post_records']\n",
    "\n",
    "    # If there is a post_records call, ask for user confirmation\n",
    "    if len(post_record_calls) > 0:\n",
    "\n",
    "        # Get the confirmation message from the tool call arguments and ask the user to review\n",
    "        confirmation_message = [call[\"args\"][\"confirmation_message\"] for call in post_record_calls]\n",
    "        user_review = interrupt({\"task\": \"Review the action.\",\n",
    "                           \"action\": confirmation_message})\n",
    "        \n",
    "        # Use the verification LLM to determine if the user confirmed the action\n",
    "        output = verification_llm.invoke(\n",
    "            [('user', user_review), ('system', 'Verify whether the user wants to continue with the action.')])\n",
    "        # Extract the user affirmation result\n",
    "        should_continue = output.tool_calls[0]['args']['user_affirmation']\n",
    "        print(f\"Model explanation: {output.tool_calls[0]['args']['explanation']}\")\n",
    "\n",
    "        # If user confirmed, proceed to tools node, else go back to agent node\n",
    "        if should_continue:\n",
    "            # With Send we can select the next node and pass the current state\n",
    "            return Send(node='tools', arg=state)\n",
    "        else:\n",
    "            # With Command we can select the next node and update the state\n",
    "            return Command(update={\"messages\": [ToolMessage('User did not confirm action.', tool_call_id=call['id']) for call in post_record_calls]}, goto='agent')\n",
    "    else:\n",
    "        return Send(node='tools', arg=state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Determine the Next Node**\n",
    "\n",
    "Understand the logic of the `human_review` node, decide which node the graph will transition to in each of the following scenarios. Fill in the blanks before revealing the answers.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "1.  **Scenario A:**\n",
    "    -   Last AI tool calls: `[get_records]`\n",
    "    -   Next node: _______\n",
    "\n",
    "2.  **Scenario B:**\n",
    "    -   Last AI tool calls: `[post_records(...)]`\n",
    "    -   User affirms (`should_continue = True`)\n",
    "    -   Next node: _______\n",
    "\n",
    "3.  **Scenario C:**\n",
    "    -   Last AI tool calls: `[post_records(...)]`\n",
    "    -   User declines (`should_continue = False`)\n",
    "    -   Next node: _______\n",
    "\n",
    "<details>\n",
    "<summary>Show Answers</summary>\n",
    "\n",
    "1.  **Scenario A** -> `tools`\n",
    "2.  **Scenario B** -> `tools`\n",
    "3.  **Scenario C** -> `agent`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the tools node we use the prebuilt ToolNode. It retrieves the tool calls from the last AIMessage and executes them. It provides a tool message for every tool call and appends it to the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools = [post_records, get_today, get_records]\n",
    "agent_llm = llm.bind_tools(agent_tools)\n",
    "\n",
    "tool_node = ToolNode(agent_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build our graph by adding the nodes and edges. Edges define what nodes to execute next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKDxwPl9fc3RhcnRfXzwvcD4pCglhZ2VudChbYWdlbnRdKTo6Omxhc3QKCXRvb2xzKHRvb2xzKQoJaHVtYW5fcmV2aWV3KGh1bWFuX3JldmlldykKCV9fc3RhcnRfXyAtLT4gYWdlbnQ7Cgl0b29scyAtLT4gYWdlbnQ7CglodW1hbl9yZXZpZXcgLS4tPiBhZ2VudDsKCWh1bWFuX3JldmlldyAtLi0+IHRvb2xzOwoJY2xhc3NEZWYgZGVmYXVsdCBmaWxsOiNmMmYwZmYsbGluZS1oZWlnaHQ6MS4yCgljbGFzc0RlZiBmaXJzdCBmaWxsLW9wYWNpdHk6MAoJY2xhc3NEZWYgbGFzdCBmaWxsOiNiZmI2ZmMKPC9kaXY+CiAgICA8c2NyaXB0IHNyYz0iaHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L25wbS9tZXJtYWlkL2Rpc3QvbWVybWFpZC5taW4uanMiPjwvc2NyaXB0PgogICAgPHNjcmlwdD5tZXJtYWlkLmluaXRpYWxpemUoeyBzdGFydE9uTG9hZDogdHJ1ZSB9KTs8L3NjcmlwdD4KICAgIDwvYm9keT48L2h0bWw+CiAgICA=\"\n",
       "    style=\"width:100%;height:320px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def init_agent(tool_node):\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    workflow.add_node('agent', agent)\n",
    "    workflow.add_node('tools', tool_node)\n",
    "    workflow.add_node('human_review', human_review)\n",
    "\n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    return workflow\n",
    "\n",
    "workflow = init_agent(tool_node)\n",
    "\n",
    "#Mermaid API is experiencing issues currently. Hotfix\n",
    "# display(workflow.compile())\n",
    "\n",
    "# Here you can see the current graph structure with the new human_review node.\n",
    "# As you can see the agent node is not connected to anything yet.\n",
    "display_graph(workflow.compile())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional edges define what node to execute next based on a condition. We add a conditional edge which routes the execution from the agent node either to the review node or the end node depending on whether the language model executed a tool call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCWh1bWFuX3JldmlldyhodW1hbl9yZXZpZXcpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJX19zdGFydF9fIC0tPiBhZ2VudDsKCXRvb2xzIC0tPiBhZ2VudDsKCWFnZW50IC0uICZuYnNwO3Rvb2wgY2FsbCZuYnNwOyAuLT4gaHVtYW5fcmV2aWV3OwoJYWdlbnQgLS4tPiBfX2VuZF9fOwoJaHVtYW5fcmV2aWV3IC0uLT4gYWdlbnQ7CglodW1hbl9yZXZpZXcgLS4tPiB0b29sczsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:320px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0:\n",
    "        return \"tool call\"\n",
    "    return \"__end__\"\n",
    "\n",
    "workflow.add_conditional_edges(source=\"agent\", path=should_continue, path_map={\"tool call\": \"human_review\", \"__end__\": END})\n",
    "\n",
    "\n",
    "# display(workflow.compile())\n",
    "display_graph(workflow.compile())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compile our graph. When compiling we add a checkpointer to achieve thread level persistence. With a checkpointer specified at compilation, a snapshot of the graph state is saved at every superstep. This is crucial for human-in-the-loop interactions as we need to resume execution after an interrupt is called. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <iframe\n",
       "    sandbox=\"allow-scripts\"\n",
       "    src=\"data:text/html;base64,PCFkb2N0eXBlIGh0bWw+CiAgICA8aHRtbD48aGVhZD48bWV0YSBjaGFyc2V0PSJ1dGYtOCI+PC9oZWFkPgogICAgPGJvZHk+CiAgICA8ZGl2IGNsYXNzPSJtZXJtYWlkIj4tLS0KY29uZmlnOgogIGZsb3djaGFydDoKICAgIGN1cnZlOiBsaW5lYXIKLS0tCmdyYXBoIFREOwoJX19zdGFydF9fKFs8cD5fX3N0YXJ0X188L3A+XSk6OjpmaXJzdAoJYWdlbnQoYWdlbnQpCgl0b29scyh0b29scykKCWh1bWFuX3JldmlldyhodW1hbl9yZXZpZXcpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJX19zdGFydF9fIC0tPiBhZ2VudDsKCXRvb2xzIC0tPiBhZ2VudDsKCWFnZW50IC0uICZuYnNwO3Rvb2wgY2FsbCZuYnNwOyAuLT4gaHVtYW5fcmV2aWV3OwoJYWdlbnQgLS4tPiBfX2VuZF9fOwoJaHVtYW5fcmV2aWV3IC0uLT4gYWdlbnQ7CglodW1hbl9yZXZpZXcgLS4tPiB0b29sczsKCWNsYXNzRGVmIGRlZmF1bHQgZmlsbDojZjJmMGZmLGxpbmUtaGVpZ2h0OjEuMgoJY2xhc3NEZWYgZmlyc3QgZmlsbC1vcGFjaXR5OjAKCWNsYXNzRGVmIGxhc3QgZmlsbDojYmZiNmZjCjwvZGl2PgogICAgPHNjcmlwdCBzcmM9Imh0dHBzOi8vY2RuLmpzZGVsaXZyLm5ldC9ucG0vbWVybWFpZC9kaXN0L21lcm1haWQubWluLmpzIj48L3NjcmlwdD4KICAgIDxzY3JpcHQ+bWVybWFpZC5pbml0aWFsaXplKHsgc3RhcnRPbkxvYWQ6IHRydWUgfSk7PC9zY3JpcHQ+CiAgICA8L2JvZHk+PC9odG1sPgogICAg\"\n",
       "    style=\"width:100%;height:320px;border:0;\">\n",
       "    </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "checkpointer = MemorySaver()\n",
    "timesheet_agent = workflow.compile(checkpointer=checkpointer)\n",
    "display_graph(timesheet_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensure consistent and useful behaviour we need to define a well structured system prompt next. \n",
    "Generally, you should:\n",
    "  1. Define the role and persona.\n",
    "  2. Establish context and objectives\n",
    "  3. Outline clear instructions and constraints\n",
    "  4. Provide examples of ideal responses (Optional)\n",
    "\n",
    "\n",
    "By utilizing few-shot prompting model performance can be hugely improved. It also makes sense to encourage iterative clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"\n",
    "Role and Objective:\n",
    "\n",
    "  - You are a helpful AI Agent dedicated to assisting users with their timesheet management.\n",
    "  - Your primary tasks include retrieving and posting timesheet data based on user requests.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "  - Logging Work Time: Only log actual work time. Do not include any breaks.\n",
    "    - User: Today I worked from 6 to 16 with a half hour break at 12. -> You should: Log time from 6 to 12 and from 12:30 to 16.\n",
    "  - Data Handling: When posting records, execute as many post_records calls in parallel as possible using the provided information.\n",
    "  - Automatic Confirmation: When a post_records call is made, the user is automatically asked for confirmation over a GUI; do not prompt for confirmation.\n",
    "\n",
    "Interaction Guidelines:\n",
    "\n",
    "  - The user's most recent input always takes precedence over older input.\n",
    "  - Language Consistency: Always respond in the same language as the user.\n",
    "  - Clarity and Accuracy:\n",
    "    - If any part of the user’s request is ambiguous (for example, missing dates or unclear work times), ask clarifying questions rather than making assumptions.\n",
    "    - Ensure all necessary details are provided before proceeding with any action.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    MessagesPlaceholder(variable_name='msg')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output(stream):\n",
    "    for token in stream: \n",
    "        (key, content), = token.items()\n",
    "        if key == \"__interrupt__\":\n",
    "           print(content[0])\n",
    "           return True \n",
    "        if content is not None:\n",
    "           content['messages'][-1].pretty_print()\n",
    "    print(\"\\n\")\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can stream the output of our agent. We hand over a dictionary containing the user's input and a config with our thread id. Each thread represents an individual session betweeen the graph and the user. So, if we want to continue our conversation, we need to pass the same thread id to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "To log your work time accurately, I will split your work hours into two segments: from 6:00 to 12:00 and from 12:30 to 18:00.\n",
      "\n",
      "First, let me retrieve today's date.\n",
      "Tool Calls:\n",
      "  get_today (call_GN9FQSFDeQZiSQubXotFkSZI)\n",
      " Call ID: call_GN9FQSFDeQZiSQubXotFkSZI\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_today\n",
      "\n",
      "2025-09-24\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "Tool Calls:\n",
      "  post_records (call_wa8OvjQKqSuv0kjxjEKHNMoa)\n",
      " Call ID: call_wa8OvjQKqSuv0kjxjEKHNMoa\n",
      "  Args:\n",
      "    data: {'startDate': '2025-09-24', 'startTime': 'PT06H00M00S', 'endTime': 'PT12H00M00S'}\n",
      "    confirmation_message: Log work time from 6:00 to 12:00 on 2025-09-24\n",
      "  post_records (call_P7QfpqSvLi0C5d2iEFZnrfQF)\n",
      " Call ID: call_P7QfpqSvLi0C5d2iEFZnrfQF\n",
      "  Args:\n",
      "    data: {'startDate': '2025-09-24', 'startTime': 'PT12H30M00S', 'endTime': 'PT18H00M00S'}\n",
      "    confirmation_message: Log work time from 12:30 to 18:00 on 2025-09-24\n",
      "Interrupt(value={'task': 'Review the action.', 'action': ['Log work time from 6:00 to 12:00 on 2025-09-24', 'Log work time from 12:30 to 18:00 on 2025-09-24']}, resumable=True, ns=['human_review:030a5e4e-0aa1-2ab9-e0df-537d0c9ce11e'], when='during')\n",
      "Model explanation: The user has confirmed the action by stating 'Sure.'\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: post_records\n",
      "\n",
      "Entity created successfully: {'startDate': '2025-09-24', 'startTime': 'PT12H30M00S', 'endTime': 'PT18H00M00S'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "Your work time has been successfully logged:\n",
      "\n",
      "- From 6:00 to 12:00 on 2025-09-24.\n",
      "- From 12:30 to 18:00 on 2025-09-24.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid1())}}\n",
    "\n",
    "user_input = {'messages': ['user', 'Today, I worked from 6 to 6 with a half hour break at 12.']}\n",
    "process_output(timesheet_agent.stream(user_input, config, stream_mode='updates'))\n",
    "\n",
    "user_input = Command(resume='Sure.')\n",
    "process_output(timesheet_agent.stream(user_input, config, stream_mode='updates'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try interacting with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to interact with the agent (type q to quit):\n",
      "\n",
      "hi\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "Hello! How can I assist you with your timesheet management today?\n",
      "\n",
      "\n",
      "who are you\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "I am a helpful AI Agent dedicated to assisting you with your timesheet management. How can I help you today?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid1())}}\n",
    "interrupted = False\n",
    "\n",
    "print(\"Type to interact with the agent (type q to quit):\\n\")\n",
    "while True:\n",
    "    user_input = input()\n",
    "    if user_input.lower() == 'q':\n",
    "        break\n",
    "    print(user_input)\n",
    "\n",
    "    if interrupted:\n",
    "        interrupted = False\n",
    "        user_input = Command(resume=user_input)\n",
    "    else:\n",
    "        user_input = {'messages': ['user', user_input]}\n",
    "\n",
    "    interrupted = process_output(timesheet_agent.stream(user_input, config, stream_mode=\"updates\"))\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension with MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tools from MCP server. Available tools: ['search_messages', 'get_message']\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please check my email inbox.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "Tool Calls:\n",
      "  search_messages (call_TV11td73cDJWzFbmjiGOkqWw)\n",
      " Call ID: call_TV11td73cDJWzFbmjiGOkqWw\n",
      "  Args:\n",
      "    limit: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_messages\n",
      "\n",
      "[{\"id\":\"1994d12b9574738a\",\"thread_id\":\"1994d12b9574738a\",\"subject\":\"Workshop Notes\",\"from\":\"\\\"Abdulla, Can\\\" <can.abdulla@sap.com>\",\"date\":\"Mon, 15 Sep 2025 11:11:30 +0000\",\"preview_text\":\"Hi Alice,\\r\\n\\r\\nThanks for the workshop today from 14:00–16:00 with our team.\\r\\nPlease send the notes wh...\"},{\"id\":\"1995eef92570bc1e\",\"thread_id\":\"1995eef92570bc1e\",\"subject\":\" Business Tip: Show up on Google Search and Maps\",\"from\":\"Google Community Team <googlecommunityteam-noreply@google.com>\",\"date\":\"Thu, 18 Sep 2025 15:26:22 -0700\",\"preview_text\":\"BUSINESS TIP\\r\\n\\r\\nStand out on Google with a free Business Profile\\r\\n\\r\\nAttract customers on Google Sear...\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: agent\n",
      "\n",
      "You have two recent emails in your inbox:\n",
      "\n",
      "1. **Subject:** Workshop Notes\n",
      "   **From:** \"Abdulla, Can\" <can.abdulla@sap.com>\n",
      "   **Date:** Mon, 15 Sep 2025 11:11:30 +0000\n",
      "   **Preview:** Hi Alice, Thanks for the workshop today from 14:00–16:00 with our team. Please send the notes wh...\n",
      "\n",
      "2. **Subject:** Business Tip: Show up on Google Search and Maps\n",
      "   **From:** Google Community Team <googlecommunityteam-noreply@google.com>\n",
      "   **Date:** Thu, 18 Sep 2025 15:26:22 -0700\n",
      "   **Preview:** BUSINESS TIP Stand out on Google with a free Business Profile Attract customers on Google Sear...\n",
      "\n",
      "Would you like to read any of these emails in detail?\n"
     ]
    }
   ],
   "source": [
    "# Extension with MCP / Community Tool Kits\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Retrieve MCP token from environment variable or use default for demo purposes\n",
    "MCP_TOKEN = os.environ.get(\"MCP_TOKEN\", None)\n",
    "if MCP_TOKEN is None:\n",
    "    raise ValueError(\"MCP_TOKEN environment variable is not set.\")\n",
    "\n",
    "# Define MCP server configurations\n",
    "def http_mcp_server(url):\n",
    "    # url = url.rstrip(\"/\")\n",
    "    return {\n",
    "        \"email\": {\n",
    "            \"transport\": \"streamable_http\",\n",
    "            \"url\": url,\n",
    "            \"headers\": {\"Authorization\": f\"Bearer {MCP_TOKEN}\"}\n",
    "        }\n",
    "    }\n",
    "\n",
    "url = os.environ.get(\"MCP_API_BASE_URL\", None)\n",
    "if url is None:\n",
    "    raise ValueError(\"MCP_API_BASE_URL environment variable is not set.\")\n",
    "\n",
    "# Initialize MCP client and load email tools\n",
    "mcp = MultiServerMCPClient(http_mcp_server(url))\n",
    "email_tools = await mcp.get_tools(server_name=\"email\")\n",
    "\n",
    "# Combine with existing tools\n",
    "tools = [get_today, get_records, post_records, *email_tools]\n",
    "print(f\"Loaded tools from MCP server. Available tools: {[tool.name for tool in email_tools]}\")\n",
    "agent_llm = llm.bind_tools(tools)\n",
    "\n",
    "# Reinitialize workflow with new tools\n",
    "tools_node = ToolNode(tools)\n",
    "workflow = init_agent(tool_node=tools_node)\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"agent\",\n",
    "    path=should_continue,\n",
    "    path_map={\"tool call\": \"human_review\", \"__end__\": END}\n",
    ")\n",
    "\n",
    "# Finalize agent with checkpointer to retain state across sessions\n",
    "new_agent  = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Test the agent with email tools\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid1())}}\n",
    "answer = await new_agent.ainvoke({\"messages\": [\"Please check my email inbox.\"]}, config)\n",
    "for msg in answer[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
